{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b0dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import csv\n",
    "import sys \n",
    "sys.path.append(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b230d4a",
   "metadata": {},
   "source": [
    "Q.1. Write a function which count number of lines and number of words in a text. All the files are in the data the folder:\n",
    "\n",
    "a) Read obama_speech.txt file and count number of lines and words \n",
    "\n",
    "b) Read michelle_obama_speech.txt file and count number of lines and words\n",
    "\n",
    "c) Read donald_speech.txt file and count number of lines and words\n",
    "\n",
    "d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fb9701e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/user/Desktop/30-Days-of-Python/data/melina_trump_speech.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m             words\u001b[38;5;241m.\u001b[39mextend(line\u001b[38;5;241m.\u001b[39msplit())\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of lines and words in the file are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lines)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(words)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m respectively\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mcount_num_lines_words\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/user/Desktop/30-Days-of-Python/data/melina_trump_speech.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m count_num_lines_words(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/user/Desktop/30-Days-of-Python/data/donald_speech.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m count_num_lines_words(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/user/Desktop/30-Days-of-Python/data/michelle_obama_speech.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m, in \u001b[0;36mcount_num_lines_words\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_num_lines_words\u001b[39m(file):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     10\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     11\u001b[0m         words \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/user/Desktop/30-Days-of-Python/data/melina_trump_speech.txt'"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import sys \n",
    "sys.path.append(\"data\")\n",
    "\n",
    "def count_num_lines_words(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            words.extend(line.split())\n",
    "    print(f'The number of lines and words in the file are {len(lines)} and {len(words)} respectively')\n",
    "count_num_lines_words(\"C:/Users/user/Desktop/30-Days-of-Python/data/melina_trump_speech.txt\")\n",
    "count_num_lines_words(\"C:/Users/user/Desktop/30-Days-of-Python/data/donald_speech.txt\")\n",
    "count_num_lines_words(\"C:/Users/user/Desktop/30-Days-of-Python/data/michelle_obama_speech.txt\")\n",
    "count_num_lines_words(\"C:/Users/user/Desktop/30-Days-of-Python/data/obama_speech.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe12fe",
   "metadata": {},
   "source": [
    "Q2. Read the countries_data.json data file in data directory, create a function that finds the tenmost spoken languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124aeaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "def most_spoken_languages(file,n):\n",
    "    with open(file) as f:\n",
    "        list = json.loads(f.read())\n",
    "        # looping to get dict of languages\n",
    "        languages = []\n",
    "        for i in range(len(list)):\n",
    "            languages.extend(list[i]['languages'])\n",
    "            lang = {}\n",
    "        for language in languages:\n",
    "            lang[language] = lang.get(language,0) + 1\n",
    "            sorted_lang = sorted(lang.items(), key= lambda x:x[1],reverse=True)\n",
    "            result = [(item[1],item[0]) for item in sorted_lang]\n",
    "            return result[:n]\n",
    "print(most_spoken_languages('countries_data.json',10))\n",
    "print(most_spoken_languages('countries_data.json',3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. Read the countries_data.json data file in data directory, create a function that creates a list ofthe ten most populated countries\n",
    "def most_populated_countries(filename,n):\n",
    "    with open(filename) as f:\n",
    "        dic_list = json.loads(f.read())\n",
    "        population = dict()\n",
    "    for i in range(len(dic_list)):\n",
    "        keys = dic_list[i]['name']\n",
    "        values = dic_list[i]['population']\n",
    "        population[keys] = values\n",
    "    sorted_lt = sorted(population.items(), key= lambda x:x[1],reverse=True)\n",
    "    final_list = [{'country':item[0],'population':item[1]} for item in sorted_It]\n",
    "    return final_list[:n]\n",
    "most_populated_countries('countries_data.json',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f8735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Extract all incoming email addresses as a list from the email_exchange_big.txt file.\n",
    "def find_most_common_words(file,n=10):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "    for line in lines:\n",
    "        line = re.sub(r'[^\\w\\s]','',line)\n",
    "        words.extend(line.split())\n",
    "        words_dict = {}\n",
    "    for word in words:\n",
    "        words_dict[word] = words_dict.get(word,0) + 1\n",
    "        words_sorted = sorted(words_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "        result = [(word[1],word[0]) for word in words_sorted]\n",
    "        return result[:n]\n",
    "find_most_common_words('donald_speech.txt',5)\n",
    "\n",
    "print('Obama: ',find_most_common_words('obama_speech.txt'))\n",
    "print('Michelle Obama: ',find_most_common_words('michelle_obama_speech.text'))\n",
    "print('Donald Trump: ',find_most_common_words('donald_speech.txt'))\n",
    "print('Melina Trump: ',find_most_common_words('melina_trump_speech.text'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80496a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "def clean_text(file):\n",
    "    '''\n",
    "    Returns all the words in a text after removing the punctuations a\n",
    "    '''\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            words.extend(line.split())\n",
    "    return words\n",
    "clean_text('michelle_obama_speech.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a4044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text_similarity(list_one,list_two):\n",
    "    res = [x for x in (list_one + list_two) if x in list_one and x inlist_two] \n",
    "    similar_words_percent = (len(res)/(len(list_one) + len(list_two))) * 100\n",
    "    return similar_words_percent\n",
    "check_text_similarity(['apple','banana','mango','pawpaw'],['apple','mango', 'pear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a48cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparing_text_in_file_similarity(file_one,file_two):\n",
    "    file_one_words = remove_stop_words(clean_text(file_one))\n",
    "    file_two_words = remove_stop_words(clean_text(file_two))\n",
    "    return check_text_similarity(file_one_words,file_two_words)\n",
    "comparing_text_in_file_similarity('michelle_obama_speech.txt','melania_trump_speech.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55986ef2",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1704f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8  Find the 10 most repeated words in the romeo_and_juliet.txt\n",
    "from collections import Counter\n",
    "import re\n",
    "f = open(\"C:\\Users\\user\\Desktop\\30-Days-of-Python\\data\\romeo_and_juliet.txt\")\n",
    "words = re.findall('\\w+', text)\n",
    "print(counter(words).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1e3aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9\n",
    "with open('hacker_news.csv',newline='') as f:\n",
    "    csv_reader = csv.reader(f,delimiter=',')\n",
    "    python_rows = 0\n",
    "    javascript_rows = 0\n",
    "    java_rows = 0\n",
    "    for row in csv_reader:\n",
    "        for i in range(len(row)):\n",
    "            if re.findall(r'[Pp]ython',row[i]):\n",
    "                python_rows += 1\n",
    "            elif re.findall(r'[Jj]ava[Ss]cript',row[i]):\n",
    "                javascript_rows +=1\n",
    "            elif re.findall(r'Java$',row[i]):\n",
    "                java_rows +=1\n",
    "print(f'the number of lines containing a,b and c respectively are: {python_rows}, {javascript_rows}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
